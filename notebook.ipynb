{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author: Bourahima COULIBALY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subject:\n",
    "#### Context\n",
    "\n",
    "Modjo is a Conversational Intelligence platform that helps its clients to leverage their customer interactions (audio calls and video calls) to coach their client facing teams, share key insights with the rest of the company, and keep business data accurate and relevant (notably by filling CRM fields). \n",
    "\n",
    "Given how audio and video recording are deep to dive in and long to listen to, being able to extract the key insights to bring to the attention of the users is crucial. \n",
    "\n",
    "In this small exercise you will work on how to summarize information from a call. This summary would be displayed next to the call playback, sent to the CRM etc.\n",
    "\n",
    "#### Exercice\n",
    "\n",
    "Using python and by making your code clean, organized and documented, please perform the following tasks. You can apply it to the provided transcript. \n",
    "\n",
    "Deliverable includes:\n",
    "\n",
    "- A zip file of the functional python project\n",
    "- A document with explanations and results of run on the provided transcript. Chose whatever format suits you best, Jupyter Notebook, PDF from a text editor, slides…\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from openai import OpenAI\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we have decided to pre-process our data to use only relevant information, in order to generate a summary and answer users' questions.\n",
    "\n",
    "We therefore need to extract the essential information, i.e. the speaker's name and the content of the conversation. Timestamps and other data are not required when we rearrange the conversation in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataExtractor:\n",
    "    \"\"\"\n",
    "    This class is designed to extract, transform, and format conversation data from a specified API.\n",
    "\n",
    "    Attributes:\n",
    "        API_URL (str): The URL of the API to fetch data from. \n",
    "        session (requests.Session): A session object for making HTTP requests.\n",
    "        res (List[Dict[str, Any]]): Raw data extracted from the API.\n",
    "        data (pd.DataFrame): Processed data stored as a pandas DataFrame.\n",
    "\n",
    "    Methods:\n",
    "        extract_data() -> None:\n",
    "            Fetches data from the API and stores it in self.res.\n",
    "\n",
    "        transform_data() -> pd.DataFrame:\n",
    "            Processes the raw data into a structured DataFrame.\n",
    "\n",
    "        data_frame_to_text() -> str:\n",
    "            Converts the DataFrame to a formatted text string.\n",
    "\n",
    "        dataframe_to_json() -> json:\n",
    "            Converts the DataFrame to a JSON string.\n",
    "\n",
    "        get_conversation_data(format: str = 'dataframe') -> Any:\n",
    "            Returns the conversation data in the specified format.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, api_url: str = None):\n",
    "        \"\"\"\n",
    "        Initializes the DataExtractor with an optional API URL.\n",
    "\n",
    "        Args:\n",
    "            api_url (str, optional): The URL of the API to fetch data from.\n",
    "                                    If not provided, a default URL is used.\n",
    "        \"\"\"\n",
    "        self.API_URL = api_url or \"https://file.notion.so/f/f/a81bac85-8169-4578-8cb9-a0c53a5432d9/368a9500-48b4-4c7d-a82d-dd00f0b4e61f/segments_(4).json?id=36bd1e43-fbfa-4f7f-b3f1-42b2609f3100&table=block&spaceId=a81bac85-8169-4578-8cb9-a0c53a5432d9&expirationTimestamp=1719568800000&signature=t5MQ1qg7ezFEzpGfzTPXTflJvJHBGZ-XziORO8C9Ruk&downloadName=demo-segments.json\"\n",
    "        self.session = requests.Session()\n",
    "        self.res: List[Dict[str, Any]] = []\n",
    "        self.data: pd.DataFrame = pd.DataFrame()\n",
    "\n",
    "    def extract_data(self) -> None:\n",
    "        \"\"\"\n",
    "        Extracts data from the API and stores it in self.res.\n",
    "\n",
    "        Raises:\n",
    "            requests.RequestException: If there's an error during the API request.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.session.get(self.API_URL)\n",
    "            response.raise_for_status()\n",
    "            res = response.json()\n",
    "            self.res = res.get(\"segments\", [])\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"Erreur lors de l'extraction des données: {e}\")\n",
    "            self.res = []\n",
    "\n",
    "    def transform_data(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Transforms the extracted data into a structured DataFrame.\n",
    "\n",
    "        This method processes the raw data, combining consecutive entries\n",
    "        from the same speaker and removing duplicates.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The processed data as a pandas DataFrame.\n",
    "        \"\"\"\n",
    "        if not self.res:\n",
    "            self.extract_data()\n",
    "        \n",
    "        data = [{\"speaker\": item.get(\"speaker\"), \"content\": item.get(\"content\")} \n",
    "                for item in self.res]\n",
    "        data = pd.DataFrame(data)\n",
    "\n",
    "        indexes_to_drop = []\n",
    "\n",
    "        for ligne in range(data.shape[0] - 1):\n",
    "            if data.iloc[ligne, 0] == data.iloc[ligne + 1, 0]:\n",
    "                # Combiner les contenus des lignes successives ayant le même speaker\n",
    "                data.at[ligne, 'content'] = data.at[ligne, 'content'] + \" \" + data.at[ligne + 1, 'content']\n",
    "                indexes_to_drop.append(ligne + 1)\n",
    "\n",
    "        # Supprimer les lignes marquées pour suppression\n",
    "        data = data.drop(indexes_to_drop)\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        return self.data\n",
    "\n",
    "    def data_frame_to_text(self) -> str:\n",
    "        \"\"\"\n",
    "        Converts the DataFrame to a formatted text string.\n",
    "\n",
    "        Returns:\n",
    "            str: A string representation of the conversation, with each line\n",
    "                formatted as \"speaker: content\".\n",
    "        \"\"\"\n",
    "        if self.data.empty:\n",
    "            self.transform_data()\n",
    "        \n",
    "        return \"\\n\".join(f\"{row.speaker}: {row.content}\" for _, row in self.data.iterrows())\n",
    "\n",
    "    def dataframe_to_json(self) -> json:\n",
    "        \"\"\"\n",
    "        Converts the DataFrame to a JSON string.\n",
    "\n",
    "        Returns:\n",
    "            json: A JSON string representation of the DataFrame.\n",
    "        \"\"\"\n",
    "        if self.data.empty:\n",
    "            self.transform_data()\n",
    "        \n",
    "        return self.data.to_json(orient='records')\n",
    "\n",
    "    def get_conversation_data(self, format: str = 'dataframe') -> Any:\n",
    "        \"\"\"\n",
    "        Returns the conversation data in the specified format.\n",
    "\n",
    "        Args:\n",
    "            format (str): The desired output format. \n",
    "                        Options are 'dataframe', 'text', or 'json'.\n",
    "\n",
    "        Returns:\n",
    "            Any: The conversation data in the requested format.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If an unsupported format is specified.\n",
    "        \"\"\"\n",
    "        if format == 'dataframe':\n",
    "            return self.transform_data()\n",
    "        elif format == 'text':\n",
    "            return self.data_frame_to_text()\n",
    "        elif format == 'json':\n",
    "            return self.dataframe_to_json()\n",
    "        else:\n",
    "            raise ValueError(\"Format non supporté. Utilisez 'dataframe', 'text', ou 'json'.\")\n",
    "\n",
    "dataextractor = DataExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spk2</td>\n",
       "      <td>Oui bonjour Celeste.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spk0</td>\n",
       "      <td>Bonjour Merlin. Comment vas-tu ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spk2</td>\n",
       "      <td>Très bien et toi ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spk0</td>\n",
       "      <td>Super. Écoute, ça va super. Je suis ravie de c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spk2</td>\n",
       "      <td>Non, là je t'avoue que avec le gros brume que ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  speaker                                            content\n",
       "0    spk2                               Oui bonjour Celeste.\n",
       "1    spk0                   Bonjour Merlin. Comment vas-tu ?\n",
       "2    spk2                                 Très bien et toi ?\n",
       "3    spk0  Super. Écoute, ça va super. Je suis ravie de c...\n",
       "4    spk2  Non, là je t'avoue que avec le gros brume que ..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataextractor.get_conversation_data()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_json = dataextractor.get_conversation_data(format='json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spk2: Oui bonjour Celeste.\n",
      "spk0: Bonjour Merlin. Comment vas-tu ?\n",
      "spk2: Très bien et toi ?\n",
      "spk0: Super. Écoute, ça va super. Je suis ravie de commencer mon après-midi avec toi. Je vois que la caméra n'a pas été réparée. Je sais pas si t'es tout seul ou t'es avec...\n",
      "spk2: Non, là je t'avoue que avec le gros brume que j'ai...\n",
      "spk0: Ah oui ! Ok, pas de problème. Non, mais je ne savais pas si du coup, Arthur et l'autre Merlin se connectaient derrière toi ou s'il y avait d'autres personnes qui arrivaient.\n",
      "spk2: Non, alors Merlin, je ne sais pas, mais Arthur, ben voilà, il est là, parfait.\n",
      "spk0: Ben voilà. Bonjour Arthur, enchanté. Salut Arthur.\n",
      "spk1: Je suis là, bonjour Celeste.\n",
      "spk2: Ah c'est Merlin, parfait. Donc, je suis juste contente de reposer le contexte par rapport à notre échange de la dernière fois et puis l'objectif de cette petite call tous ensemble.\n",
      "spk0: Oui, effectivement, l'idée c'était, si ça vous va, l'agenda du coup juste que je vous propose effectivement, c'est peut-être juste de faire un petit tour de table avant pour connaître un peu du coup le niveau de connaissance de Merlin et\n",
      "spk2: La caméra, je vais voir si elle fonctionne.\n",
      "spk0: OK, génial, trop cool. OK, ça va super. C'est sympa. Merci. Comme ça, plus qu'en plus, on est trois. Comme ça, je suis sûre. Si vous avez des questions, peut être aussi d'avoir le visuel. Juste avant du coup de\n",
      "spk2: Et bien, on a radé un petit peu, donc c'était pour améliorer les performances commerciales, notamment grâce à l'IA. En gros, c'est par rapport à un script, voir à quel degré de similitude on est par rapport au script. Et\n",
      "spk1: Ouais, moi, je m'occupe de toute la partie opérationnelle. Je suis associé à Merlin qui est ici dans la call et connaissance de Modjo au même moment avec Merlin, puisque c'est on était dans la même réunion le jour où\n",
      "spk0: OK, génial. Et du coup, justement, je crois que vous avez passé pas mal de temps ces dernières semaines ou ces derniers jours chez Furnitures. Est ce que vous avez pu échanger avec SquareChair? Enfin, du coup, je crois que\n",
      "spk1: Non, on n'a pas parlé avec Lancelot spécialement sur ça, je t'avoue.\n",
      "spk0: OK, non, mais pas de problème. C'était par curiosité. OK, super clair.\n",
      "spk1: Pour le savoir, on se gardera avec lui la semaine prochaine.\n",
      "spk0: Écoutez, bah écoutez, avec plaisir, effectivement, ces équipes l'utilisent. Depuis, c'était mon premier client parce que moi, je suis à eux depuis trois mois maintenant et du coup, qui de mieux qu'un utilisateur Modjo pourra vous partager des insights. Donc,\n",
      "spk2: Non, tu as très bien résumé.\n",
      "spk0: OK, génial. Et qu'est ce que je veux dire? Oui, non, dernier dernier aspect. Du coup, on avait à parler un tout petit peu moins de ça la dernière fois, Merlin, j'étais curieuse de savoir aujourd'hui concrètement qu'est ce que\n",
      "spk2: Pas grand chose. Ce n'est pas le problème. Donc, sur la partie CSM, on met en place depuis un mois, un mois et demi des tests de pitch juste sur la partie pitch démo fonctionnel. Donc, on faut qu'on garde\n",
      "spk1: On fait principalement des workshops. OK. Des workshops en règle générale, c'est une fois par mois.\n",
      "spk0: Ça se matérialise comment? Concrètement, ces workshops, c'est quoi l'objectif?\n",
      "spk1: C'est en gros, moi, je demande, donc il y a des ateliers à Ringover qui nous permettent de les écouter.\n",
      "spk0: Ouais.\n",
      "spk1: Workshop. On travaille comme ça, notamment beaucoup. Le traitement des objections. Voilà, c'est aujourd'hui, c'est la méthode où qui est qui est qui est faite côté sales. Donc, c'est une fois par mois. Sachant que ça, effectivement, ça c'est là\n",
      "spk0: Et du coup, juste petite question. Que ça soit sur les sales qui ont déjà eu leur phase de ramp-up ou les junior aujourd'hui, donc, effectivement, ils testent le pitch, ils répondent à des objections. Concrètement, là, tu fais comment\n",
      "spk1: Nous, en gros, on a un suivi hebdo. Le lundi, on a une réunion d'équipe. Le vendredi, on a une réunion individuelle. En réunion individuelle, ils ont pris l'habitude de venir avec leur, entre guillemets, avec leurs problématiques, leurs objections.\n",
      "spk0: Tu vas aller chercher combien en taux de conversion aujourd'hui ? Pardon ? Tu vas aller chercher combien en taux de conversion aujourd'hui ? Enfin, vous êtes à combien en taux de conversion et tu vas aller chercher combien dans\n",
      "spk1: En gros, aujourd'hui, on veut aller... On a nous un gros top service qui est la customize, la marque blanche chez nous. Si tu regardes un petit peu...\n",
      "spk0: Ici, j'ai regardé votre site à 139 euros.\n",
      "spk1: Voilà, notre objectif, c'est d'être tous les mois au moins 10. Donc, ça, c'est vraiment notre objectif d'être à 10.\n",
      "spk0: Et aujourd'hui, vous êtes à combien ?\n",
      "spk1: Aujourd'hui, on tourne entre 6 et 8 en gros. Donc, on est un cran en dessous. Ce mois-ci, on va aller faire les 10 parce qu'on sort d'un salon.\n",
      "spk0: En termes de chiffre d'affaires ou de MRR ou ARR à aller chercher sur l'année, tu as une idée de ce que ça représenterait d'augmenter justement cette performance qui est aujourd'hui pas forcément stable de moins en moins.\n",
      "spk1: C'est-à-dire le fait d'atteindre l'objectif, qu'est-ce que ça apporte ton MRR en plus ?\n",
      "spk0: Aujourd'hui, c'est quoi ton objectif ? C'est quoi le manque à gagner en termes d'ARR que tu as en visibilité le fait de ne pas être à 10 aujourd'hui ?\n",
      "spk1: Tu peux parler de son MRR.\n",
      "spk0: MRR, oui.\n",
      "spk1: C'est un jeu galère quand il met son niveau. Là, c'est simple. On a fait 7 marques blanches en septembre. L'objectif, c'est 10. C'est à peu près 500 euros par mois la marque blanche. C'est 1500 euros mensuels qui tournent\n",
      "spk0: Et du coup, ça c'est par sales ? Pour l'équipe ? Au global ?\n",
      "spk1: Le sales doit faire 3 marques blanches par mois. Si on voudrait qu'ils soient au niveau, il faut qu'ils fassent 3 marques blanches par mois. Normalement, s'ils en font 3 par mois, sachant que moi également j'en fais aussi, ça\n",
      "spk2: Attention, ça c'est nos chiffres aujourd'hui. Les chiffres de TAM4, c'est pas ce que ça donne. On leur fait le calcul avec Samuel pas plus tard que ce matin.\n",
      "spk0: Ça serait plutôt combien du coup ?\n",
      "spk2: Là, on serait plutôt à nombre de marques blanches par personne par mois, 5.\n",
      "spk1: Par mois, c'est pas possible. T'es à 15 marques blanches.\n",
      "spk2: Si on veut suivre ce qu'on est censé progresser, comment on est censé progresser, en tout cas sur 2024, on devrait être à terme à ce nombre-là. Dans tous les cas, on a un gros gap entre haut et bas.\n",
      "spk0: Il y a un gros gap. On parle juste de marques blanches. Les autres sont complètement dépriorisés ? Est-ce que vos sales performent plus sur les autres ?\n",
      "spk1: Là-dessus, Celeste, c'est compliqué parce que tu poses des questions auxquelles on n'a pas de réponse.\n",
      "spk0: Ok, pas de problème.\n",
      "spk1: La question est pertinente, mais tu poses des questions auxquelles on n'a pas de réponse.\n",
      "spk0: Ok, c'est pas grave.\n",
      "spk1: Le problème, c'est que le sales contribue à la vente de licence les deux autres, sauf qu'on ne sait pas le traquer. On ne sait pas pourquoi nos clients, quand le sales leur donne un code, ils ne l'utilisent pas\n",
      "spk0: Traquer dans un call, tel ou tel offre, ça vous permettrait d'avoir plus de visibilité sur ce qui pourrait être poussé par vos sales ?\n",
      "spk1: Oui, identifier ce qui a été vendu dans le call et être capable de dire que c'était Jacky qui a vendu ça. Oui, ça peut être intéressant.\n",
      "spk0: Ok, clairement, c'est un truc que je n'avais pas en tête, donc je vous montrerai. J'ai une dernière question et après, je vous promets, on switch sur la démo, mais on n'a pas trop parlé du coup de la partie\n",
      "spk2: Je pense qu'on peut rester sur le périmètre size.\n",
      "spk0: Size, ok.\n",
      "spk2: Très clair. Le démo, effectivement, peut l'améliorer, mais la personne est déjà sur le produit et c'est des informations qu'on vient lui donner. Donc oui, il y a de l'amélioration à faire, mais là pour la démo, je pense qu'on\n",
      "spk0: Ok, donc, focussons dans ce cas-là sur les sales. On n'avait pas sur la partie compte rendu, prise de notes. Tu me disais, Merlin, pendant le dernier échange que\n",
      "spk1: C'est dans les deux sens. Aujourd'hui, on n'est pas bon dans les deux sens, dans le sens où le sales n'a pas tout le temps pris les notes et souvent le CS ne prend pas les notes du tout en\n",
      "spk0: Ok, je mets les pieds là où il ne faut pas, mais l'idée, c'est de faire en sorte que ça ne se passe plus.\n",
      "spk1: C'est clair que les notes, c'est quelque chose qui est très important.\n",
      "spk0: Ok. Du coup, aujourd'hui, vous savez pourquoi ce n'est pas fait ?\n",
      "spk1: Pourquoi ce n'est pas fait ? Parce qu'en fait, le CS, il a du mal à le faire parce qu'il fait sa démo en live avec son ordinateur. Et du coup, pour faire son CR, il faut qu'il s'arrête 5\n",
      "spk0: Et côté sales sur la partie call ?\n",
      "spk1: Alors côté sales, j'allais dire chez les sales, c'est peut-être l'endroit où c'est peut-être le plus fait parce que déjà, il est libre même. Donc en fait, un sales pour lui-même, il va prendre des notes.\n",
      "spk0: Ok, écoutez, très clair, dans ce cas-là, on regardera bien cet aspect aide à la prise de notes qui aidera du coup les deux équipes. Est-ce que vous avez des choses à rajouter ou est-ce qu'on peut passer du coup\n",
      "spk2: Non, c'est complet.\n",
      "spk0: Ok, génial. Merci en tout cas pour ce complément d'information qui va très certainement enrichir cette démo. Je vous partage dès maintenant mon écran, est-ce que vous le voyez bien ?\n",
      "spk2: Oui.\n",
      "spk0: Génial. Du coup, je compte sur vous pour vraiment m'arrêter si vous avez des questions et de me dire si jamais vous voulez passer parce que ça ne vous intéresse pas particulièrement. Normalement, j'ai bien préparé, donc ça ne devrait\n",
      "spk2: Excusez-moi, Celeste, les CS font beaucoup de Google Meet ?\n",
      "spk1: Oui. C'est géré ?\n",
      "spk0: Du coup, Google Meet, exactement, c'est bien pris en compte. Toutes les vidéos Google Meet vont remonter automatiquement aujourd'hui dans Modjo. On off ? On off, non. On off aujourd'hui, on n'est pas intégré à on off. En revanche, on\n",
      "spk2: Ce n'est pas grave, on off, normalement, c'est fait que pour beaucoup, pour des réceptions de SMS, pour débloquer des comptes, etc. Donc, ce n'est pas problématique.\n",
      "spk0: C'est plus de l'écrit du coup plutôt que de l'audio finalement ?\n",
      "spk2: C'est plus pour l'opérationnel que de l'échange pur avec du client.\n",
      "spk0: En tout cas, effectivement, à date, on n'a pas encore d'intégration avec on off. Du coup, à date, on ne récupérerait pas ces échanges. OK. Du coup, l'ADN de Modjo c'est d'être le plus collaboratif possible. Et du coup, que\n",
      "spk2: Oui, oui, oui.\n",
      "spk0: Ok, j'ai une idée. Alors, du coup, ce que je vous propose, c'est qu'on va partir sur le premier pilier qui est vraiment le pilier performance. Donc on va prendre du coup la performance commerciale. Aujourd'hui, vous avez des vrais\n",
      "spk1: On va avoir surtout de l'information de ce qui se passe dans les calls.\n",
      "spk0: Ok, et ce qui va se passer, c'est que par exemple, je vais prendre du coup des échanges qui ont eu lieu, par exemple, sur le quarter. Donc ce que vous pouvez voir déjà, c'est qu'il y a des tags\n",
      "spk2: Comment ces tags sont mis en fait ?\n",
      "spk0: Alors typiquement, là, c'est des appels, donc c'est des appels de prospection. Donc là, vous pouvez voir que c'est du cold call. Autrement, c'est l'intelligence artificielle.\n",
      "spk2: Comment Modjo sait que c'est du cold call ?\n",
      "spk0: Parce que c'est lié du coup à votre ringover ou à votre aircall ou à votre outil de VOIP. Ça remonte automatiquement ce tag.\n",
      "spk2: D'accord, donc c'est sur ringover et il faut mettre la bonne information.\n",
      "spk1: Quand tu raccroches… Ce qui a été dit.\n",
      "spk0: Il y a deux choses en fait. Par exemple, il y a le nom du meeting. Vous faites une intro, l'intelligence artificielle va venir identifier la typologie de rendez-vous.\n",
      "spk1: Donc là, par exemple, on a accès… Par rapport à l'intro qui a été faite, si tu présentes le produit, c'est que c'est un cold call froid. Si tu attaques directement sur une… Comme on s'est dit la dernière fois…\n",
      "spk2: Modjo sait à tous les coups classifier ses échanges.\n",
      "spk0: Il sait classifier ses échanges. Alors là, qu'est-ce qui se passe ? Parce que j'ai mis tous les appels. Ça va pas aller. Attendez. Il sait classifier ses échanges. Ces échanges, pardon. Ça m'épette en fonction de la typologie des\n",
      "spk2: Oui.\n",
      "spk0: Super. Alors maintenant, je vais reprendre aussi un call de discovery. Et là, l'idée, du coup, vous voulez suivre finalement la manière dont est pitché aujourd'hui, dont est pitché Modjo en\n",
      "spk1: Qu'est-ce que vous apportez de plus que Ringover ?\n",
      "spk0: Alors Ringover, déjà, il faut que tu sélectionnes tes appels un peu à l'aveugle, déjà. Deuxièmement, et tu ne peux pas venir focusser sur un aspect particulier de l'échange, enfin que ça soit une démo, du coup Ringover, ce\n",
      "spk1: Ouais, OK. Sauf que…, juste le moment de l'objection ou le moment OK dans le sens où… J'ai envie de dire tout\n",
      "spk0: Tout le moment de l'appel est important ?\n",
      "spk1: On a eu le chien de nos colocs qui est venu s'exploser contre la porte.\n",
      "spk0: D'accord, pas de problème.\n",
      "spk1: Pour montrer le pauvre Padi. J'allais dire, ouais, tout le moment de l'appel amène en partie à cette situation. L'appel en lui-même en complet est\n",
      "spk0: Oui, effectivement. Du coup, sur cette partie compte rendu, je vais te le montrer. Mais du coup, je vais peut-être prendre un exemple plus parlant sur un cold call. Là, ce que je voulais te montrer, c'était aujourd'hui, comment font\n",
      "spk2: Les objections, comment on va parler d'algorithme, est-ce qu'à 98%, toutes les objections sont bien remontées, sont bien détectées ?\n",
      "spk0: En fait, c'est paramétré lors de la mise en place de Modjo. Par exemple, si tu veux traquer tous les sujets où ont été apportés par exemple des concurrents, grâce au paramétrage, on va pouvoir créer un… On appelle ça\n",
      "spk2: Ça apporte de la précision sur ton appel et pour le retravailler derrière. Ça, c'est sûr. La question que je te poserai à la fin de la réunion, c'est aujourd'hui, comme tu connais notre contexte, est\n",
      "spk0: Aujourd'hui, ce que vous me disiez, c'est que vous aviez besoin justement de comprendre un peu les pitches, les réponses à des objections, tester, challenger. La l'idée de cet outil, c'est justement vous donner les moyens de réécouter, challenger, avoir\n",
      "spk1: Après, je pense que aujourd'hui, moi, ce qui m'interpelle avec Modjo c'est le temps que ça doit prendre un manager de\n",
      "spk0: Ok, alors du coup, je fais mon mea culpa parce que je pense que je n'ai pas été assez pertinente dans ma présentation. Première chose, c'est que déjà, c'est pas que pour challenger les calls, mais du coup, vous avez un\n",
      "spk1: C'est juste, je rebondirais sur la question et je pense que, alors je sais pas, on ne s'est pas parlé, mais je pense que, en fait, dans la question, c'est est-ce que nous, on n'est pas trop petit\n",
      "spk0: Ok, merci pour ces infos. Toute l'idée, c'est d'un Modjo c'est de faire gagner du temps. Donc effectivement, si tu ne l'ai pas présenté de la manière à aujourd'hui, ça te permet de faire gagner du temps. Je comprends que\n",
      "spk2: Moi en tout cas, je comprends effectivement l'utilité d'un outil avec justement cette analyse qui permet de bien découper. Et je pense que c'est dans ta deuxième partie de présentation. Qu'est ce qui peut ou Modjo peut nous challenger?\n",
      "spk0: Est ce que tu peux préciser cette question?\n",
      "spk2: Alors c'est peut être moi qui n'avais pas compris tout le permettre de l'outil. Là, le fait d'analyser les séquences et de dire ce que tu as montré tout à l'heure, effectivement, c'est super pertinent. Et à la fois pour\n",
      "spk1: Non, non, je te confirme que nous, j'avais compris comme toi, dans le sens où on pensait que l'IA, on allait rentrer un pitch, un sorte de script de base, un template. Et l'IA, elle devait dire si le\n",
      "spk2: Respecté sans forcément avoir cette notion là, mais nous challenger dessus par rapport à l'IA, à toutes les possibilités de l'IA pour améliorer notre pitch en nous faisant des propositions d'amélioration.\n",
      "spk0: OK, alors effectivement, aujourd'hui, l'IA ne va pas vous pousser du contenu. Par contre, elle vous permet d'identifier aujourd'hui quelles sont les bonnes pratiques. Donc, par exemple, si on reprend par exemple de la démo, c'est effectivement vous dire, vous\n",
      "spk2: Oui, oui, ça, c'est bien. Après, peu importe l'outil, j'ai envie de te dire que ce soit un Hubspot ou autre. Il faut que il faut que l'équipe joue le jeu pour pour que toutes les données soient le plus\n",
      "spk1: Aujourd'hui, typiquement, tu as une FAQ où le CSM a son FAQ, le CSI a son FAQ. Bon, c'est un Google Doc, si je sais pas quel type de documents.\n",
      "spk2: les démos\n",
      "spk1: qui signent, les appels qui signent, parce que c'est vrai que ça, c'est un, on va dire que c'est l'endroit où peut-être ça a le plus de sens, parce que vous êtes capable assez vite, on peut connecter à un\n",
      "spk0: Donc, ça, ce template, effectivement, il remonte automatiquement quand un appel Ringover ou un Google Meet est lancé. Donc, pour le coup, c'est pas à ton size de dire OK, il faut que je pense à avoir mon script\n",
      "spk1: C'est smart, c'est smart.\n",
      "spk0: Cette note, elle est directement du coup liée à votre à votre CRM. Elle va revenir directement dans votre opportunité, dans votre Hubspot. Ça, c'est une note qui est du coup personnalisée et qui est du coup à l'initiative du\n",
      "spk2: Et comment il sait, excuse-moi Clémence, comment il sait, Celeste, pardon, comment il sait, quelle note il faut enregistrer ou pas?\n",
      "spk1: C'est l'IA ça en tout.\n",
      "spk0: C'est l'IA, c'est en fait aujourd'hui ils ont capté sur 35 minutes de call. Ils ont capté énormément d'informations. Ils ont fait un et l'IA a fait un résumé de une synthèse de ce call avec les next steps, les\n",
      "spk2: Ça, c'est vraiment bien.\n",
      "spk0: Du coup, ça vient vraiment forcer du coup l'aspect productivité. Ça, c'est une de vos peines.\n",
      "spk1: C'est bon, Celeste, t'es revenue dans le game.\n",
      "spk0: Non, mais je suis un peu frustré pour le truc d'avant parce que si tu me dis que ça ne fait pas gagner du temps, vu qu'on vend cet outil pour ça, il y a un vrai sujet. Je regarderai\n",
      "spk2: C'est fort. Et donc la troisième étape, c'est de remplacer le commercial haha.\n",
      "spk0: C'est ça? Non, alors ça, concrètement, on veut juste faire gagner du temps aujourd'hui au manager ou au commerciaux. Au commerciaux, grâce à de la prise de notes, grâce à de la\n",
      "spk1: D'accord. Il va avoir une gâtégeance artificielle qui fait les ventes, c'est bon.\n",
      "spk0: Et bien, écoutez, pour l'instant, ce n'est pas dans la roadmap, mais je peux venir taguer mon équipe produit pour qu'il réfléchisse à ça.\n",
      "spk1: Tu peux analyser les réponses et les objections, créer un script et en avant et là, franchement.\n",
      "spk2: Non, mais je dis ça en déconnant, mais je suis persuadé que dans un an, ça le fait en tout cas pour des appels, des appels à froid basé sur des scripts de commerciaux présents qui donnent ça à manger\n",
      "spk1: On se pense enregistrer ta voix, c'est ta voix qui sera utilisée pour ces appels.\n",
      "spk2: Moi, je viens.\n",
      "spk0: Ah bon? Écoutez, c'est la première fois qu'on me dit pas c'est trop aigu et c'est pas agréable. C'est sympa de me le dire au bout de 59 minutes.\n",
      "spk1: Et tout ça pour combien?\n",
      "spk0: Et tout ça pour combien? Et bah du coup, vous avez juste avant de partir du business model. Qu'est ce que vous en avez pensé? Parce que je vous ai donné quand même pas mal d'informations là. Je suis un\n",
      "spk1: T'es bien rattrapé Celeste, t'es bien rattrapé.\n",
      "spk0: Merci pour ton soutien.\n",
      "spk1: Je ne sais pas pourquoi on discute, mais c'est quoi le budget?\n",
      "spk0: Ok, donc on parle du budget avant même de parler de VA.\n",
      "spk1: De quoi?\n",
      "spk0: De valeur. Non, mais je voudrais juste savoir en termes de valeur. Aujourd'hui, si c'est 0 euros ou même 10 balles, est ce que tu le prendrais cet outil? Est ce que tu penses que ça répond à tes peines?\n",
      "spk2: Non. Juste pour compléter ce que dit, moi je trouve que c'est un outil qui manque et fort, d'autant plus avec les features dont tu nous as parlé juste avant là, et qui je pense va évoluer encore. Donc\n",
      "spk0: Ok. En termes de user, du coup, on parlait de quoi?\n",
      "spk2: Vous m'avez dit 4, 5, 6, 7, 5, 6, 7. On mettrai que l'essai pour le moment. Donc c'est 3, 4 personnes. 4 personnes, Merlin en écoute, en analyse en manager.\n",
      "spk0: Sachant qu'Merlin, aujourd'hui, je crois que tu fais des calls. Tu me disais que tu poussais encore. Donc tu imagines que tes pratiques commerciales, elles sont quand même, c'est censé être des références pour les nouveaux arrivants et les alternants.\n",
      "spk1: Donc typiquement, j'appelle avec mon téléphone. J'appelle avec une ligne classique.\n",
      "spk0: Tu n'appelles pas avec du coup un Hubspot ou un Ringover?\n",
      "spk1: Non. Mais bon, je pourrais. Mais c'est vrai que tu vois, on a fait un challenge prospection hier et en fait, on s'aperçoit que j'ai un taux de réponse qui est vachement plus élevé que moi. Je tourne à 70%\n",
      "spk0: Et parce que RingGover, ils sont sur un 0?\n",
      "spk1: Non, ils sont sur un 0755. Mais il paraît qu'aujourd'hui, les 0755 et 0765, ils sont identifiés comme ça.\n",
      "spk0: OK. Eh ben écoute, c'est la première fois que j'entends ça.\n",
      "spk1: Bah écoute, tu vois, on l'a vu hier, les pauvres, ils étaient frustrés. Du coup, ils ont perdu le challenge.\n",
      "spk0: Mais c'est pas sympa. Ça, c'est toi qui a gagné le resto. OK. Oui, bon, du coup, pour revenir. Pour revenir au sujet, du coup, ça sera entre 4 et 5 licences, enfin, ou 4 licences.\n",
      "spk2: Si le manager est compris dedans, ça serait 5.\n",
      "spk0: OK. Mais du coup, toute la partie, donc ça serait que sur la partie call, pas du tout sur la partie vidéo.\n",
      "spk2: Alors la partie vidéo, elle est faite plus par les CSM. Donc dans un deuxième temps, parce que ça, c'est pas aujourd'hui, c'est pas le gros du sujet.\n",
      "spk0: Bah du coup, sur la partie aujourd'hui, du coup, notre business model. Du coup, notre business model, c'est à la licence enregistreuse. Donc, c'est toutes les personnes qui importent de la matière des enregistrements dans Modjo Donc là, ça serait\n",
      "spk1: Nous, on n'a pas de marge de manoeuvre. C'est toi, éventuellement, tu en as. Mais nous, on n'en a pas.\n",
      "spk0: Mais tu imagines bien que si on fait des discounts, il y a forcément des contreparties. Tu dois être meilleur sales que moi. Et du coup, j'imagine que tu as l'habitude de négocier. Du coup, les contreparties, c'est la vélocité\n",
      "spk1: Et du coup, pour les trois introductions, combien je gagne ?\n",
      "spk0: 5 %. Mais alors aujourd'hui, non, mais écoutez, aujourd'hui, là, le tout, enfin, le sujet de cet échange, c'est du coup de faire une démo et de valider aujourd'hui la valeur et de vous présenter le business model. Moi, ce\n",
      "spk2: Ouais, alors moi, je veux juste te donner une autre information. On a 18 mois pour performer. Voilà. Donc, tout budget supplémentaire qui arrive dans ces 18 mois, il faut qu'il soit justifié ou alors avoir un discount comme Hubspot\n",
      "spk0: Aujourd'hui, de toute façon, Modjo c'est pas un outil qui est mis en place parce qu'il n'y a pas de ROI. Et le ROI ne serait-ce qu'en termes de taux de conversion, si je reste juste sur le taux de\n",
      "spk2: On en a une. Oui, on en a une après de donner un montant exact. J'en serais incapable. En tout cas, c'est sûr que c'est un montant qui est vraiment minime. Je te dis avec Hubspot, on est en train\n",
      "spk0: OK. Et du coup, là, je te partageais juste.\n",
      "spk1: C'est normal de négocier Hubspot, vu ce qui nous prenne 200 euros, c'est de survoir un point. Aujourd'hui, on n'a pas de. Ce n'était pas prévu.\n",
      "spk0: Juste sur quoi tu as un doute du coup? Ce que tu m'as dit deux, trois pain, ça veut dire qu'il y en a au moins une auxquelles on n'a pas répondu.\n",
      "spk1: C'est pas que vous n'y répondez pas. C'est que, en gros, je ne sais pas si votre... Déjà, j'ai identifié des bonnes pratiques. Donc, merci. Du coup, je vais dire à mes six de faire certaines choses avec maintenant pour\n",
      "spk0: Tu as bien aimé la live note.\n",
      "spk1: Voilà, deux, trois pains. En règle générale, je perds pas le temps. Mais, mais, mais, on va voir ton offre. Et derrière, nous, on va rediscuter en interne. Mais évidemment, effectivement, du budget, il n'y en avait pas de base.\n",
      "spk0: Par mois. Oui, on y va. Là, de toute façon, là, du coup, ce que je vous disais, c'était cinq users à 99 euros. Le prix de base, c'est du coup, ça ferait un 495 de mémoire sans levier d'action.\n",
      "spk1: Voilà, je pense que comme t'as beaucoup de levier d'action, je pense que tu vas actionner plein de leviers pour que ce soit potentiellement.\n",
      "spk0: Bah, écoutez, dans ce cas là, prenons nous un créneau parce que je sais que votre temps est compté. Et du coup, ce que je vous propose, c'est qu'on se prenne un créneau pour vous présenter l'offre.\n",
      "spk1: Au pire, tu nous refais un mail et tu nous redis ou tu nous envoies ton calendrier. On prend le calendrier.\n",
      "spk0: C'est pas plus simple de croiser nos agendas maintenant.\n",
      "spk2: Non, mais je vais gérer le troisième rendez-vous.\n",
      "spk1: Voilà, parfait. OK, super.\n",
      "spk0: Allez, ça marche. Merci à tous les trois. Je reste le Celeste juste pour finir. Oui, ça marche.\n",
      "spk2: Merci. Merci Antoine. Donc, Celeste, oui, encore une fois, outil très intéressant. J'avais une autre question au niveau du on boarding. Comment ça\n",
      "spk0: Oui, alors du coup, en termes d'onboarding, du coup, effectivement, Modjo c'est 70 80% la plateforme. Mais c'est surtout que vous avez un accompte manager, donc un consultant qui est là pour vous accompagner de la paramétrage.\n",
      "spk2: Ah c'est Gymlib.\n",
      "spk0: Voilà, donc tu vas très bien connaître. Donc tu vois, ça, c'était un de nos premiers clients. Et vraiment, encore une fois, ils n'ont pas du tout mis en place Modjo quand ils étaient Gymlib de maintenant. Ils sont\n",
      "spk2: OK, OK, OK.\n",
      "spk0: J'ai bien répondu à ta question.\n",
      "spk2: J'avais saisi effectivement ça. Et sur les évolutions du produit, est-ce qu'on reste sur le même prix ou est-ce qu'on va être bloqué? Si\n",
      "spk0: Non, effectivement, il y a absolument ce qui est signé restera signé. Ce que je veux dire, c'est que c'est notamment la fonctionnalité dont je t'ai parlé. Tu vas en bénéficier. On n'a pas de coût supplémentaire en fonction des\n",
      "spk2: Parce que je te dis ça parce que Intercom, par exemple, qui est un excellent outil, il sort des fonctionnalités régulièrement et il y en a qui ne font pas partie du scope. C'est des modules en fait additionnels. C'est\n",
      "spk0: OK, effectivement, après, tu vois, sur la partie productivité, notes. Aujourd'hui, du coup, c'est l'IA qui fait tout. Et donc, pour le coup, ça remonte directement dans ton Hubspot. Donc, en fait, de toute façon, les calls, ils sont enregistrés.\n",
      "spk2: Oui.\n",
      "spk0: Qu'est ce que tu penses? Moi, j'ai un créneau demain si tu veux ou autrement lundi.\n",
      "spk2: Lundi, ce sera mieux. Lundi, lundi, lundi.\n",
      "spk1: Qu'est ce que c'est?\n",
      "spk2: Lundi 16h30.\n",
      "spk0: Eh ben parfait. Lundi 16h30. On fait ça. Je t'envoie un peu. Je t'envoie l'invit du coup. Que on sera tous les deux, c'est ça? Oui. OK, très bien. Eh ben écoute, je t'envoie l'invitation et on en discute\n"
     ]
    }
   ],
   "source": [
    "texte = dataextractor.get_conversation_data(format='text')\n",
    "\n",
    "with open(\"data/conversation.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(texte)\n",
    "\n",
    "print(texte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using GPT-3.5-turbo**, implement in python summarizers that take as input a json like the one you were provided, and that must be able to perform the following tasks:\n",
    "\n",
    "1.1  a **60-word max. summary**. \n",
    "\n",
    "1.2  a **free-format summary**. It will be used by the callers’ peers to know at a glance what happened during the call. It can be a manager who comes to coach the caller, to get information on the deal, another rep who will be involved on the deal too and needs to know what happened during the call etc. Please justify the choices you make regarding the format you choose.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address this need, we will engage in prompt engineering to find the best configuration for obtaining an optimal summary of the conversation. We will also ensure to minimize hallucinations (adding additional information not present in the original data) and improve the overall quality of the summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenAIClient:\n",
    "    \"\"\"\n",
    "    A client for interacting with the OpenAI API.\n",
    "\n",
    "    Attributes:\n",
    "        system_message (dict): The system message to be used in the chat prompt.\n",
    "        client (OpenAI): The OpenAI client instance.\n",
    "\n",
    "    Methods:\n",
    "        __init__(api_key): Initializes the OpenAI client with the given API key.\n",
    "        get_completion(prompt, model): Sends a prompt to the OpenAI API and returns the completion.\n",
    "        get_system_message(system_message): Sets the system message for the client.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, api_key=OPENAI_API_KEY):\n",
    "        \"\"\"\n",
    "        Initializes the OpenAI client.\n",
    "\n",
    "        Parameters:\n",
    "            api_key (str): The API key for the OpenAI API.\n",
    "        \"\"\"\n",
    "        self.system_message = None\n",
    "        if api_key is None:\n",
    "            raise ValueError(\"OpenAI API key is missing. Please set it in the .env file.\")\n",
    "        else:\n",
    "            self.client = OpenAI(api_key=api_key)\n",
    "        \n",
    "\n",
    "    def get_completion(self, prompt, model=\"gpt-3.5-turbo\"):\n",
    "        \"\"\"\n",
    "        Sends a prompt to the OpenAI API and returns the completion.\n",
    "\n",
    "        Parameters:\n",
    "            prompt (str): The prompt to be sent to the OpenAI API.\n",
    "            model (str): The model to be used for generating the completion. Default is \"gpt-3.5-turbo\".\n",
    "\n",
    "        Returns:\n",
    "            str: The content of the completion response.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            messages = [self.system_message, {\"role\": \"user\", \"content\": prompt}]\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                temperature=0,\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred when calling the OpenAI API: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_system_message(self, system_message):\n",
    "        \"\"\"\n",
    "        Sets the system message for the client.\n",
    "\n",
    "        Parameters:\n",
    "            system_message (dict): The system message to be used in the chat prompt.\n",
    "        \"\"\"\n",
    "        self.system_message = system_message\n",
    "\n",
    "\n",
    "class Summarizer:\n",
    "    \"\"\"\n",
    "    A summarizer for generating conversation summaries using the OpenAI API.\n",
    "\n",
    "    Attributes:\n",
    "        openai_client (OpenAIClient): An instance of the OpenAIClient.\n",
    "\n",
    "    Methods:\n",
    "        __init__(openai_client): Initializes the summarizer with the given OpenAI client.\n",
    "        summarize_60_words(texte): Generates a 60-word summary of the given conversation.\n",
    "        summarize_free_format(texte): Generates a comprehensive summary of the given conversation.\n",
    "        summarize_structured(texte): Generates a structured summary of the given conversation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, openai_client):\n",
    "        \"\"\"\n",
    "        Initializes the summarizer with the given OpenAI client.\n",
    "\n",
    "        Parameters:\n",
    "            openai_client (OpenAIClient): An instance of the OpenAIClient.\n",
    "        \"\"\"\n",
    "        self.openai_client = openai_client\n",
    "        self.openai_client.get_system_message({\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are a helpful expert on conversation summarization wizards.\"\n",
    "            )\n",
    "        })\n",
    "\n",
    "    def summarize_60_words(self, texte):\n",
    "        \"\"\"\n",
    "        Generates a 60-word summary of the given conversation.\n",
    "\n",
    "        Parameters:\n",
    "            texte (str): The conversation text to be summarized.\n",
    "\n",
    "        Returns:\n",
    "            str: The 60-word summary of the conversation.\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        You are an expert in conversation summarization. Your task is to create a concise and informative summary of the following conversation, delimited by triple backticks.\n",
    "\n",
    "        Guidelines:\n",
    "        1. Identify the key points, Persons and main themes of the conversation.\n",
    "        2. Capture the essence of the exchange, including important opinions or decisions made.\n",
    "        3. Use clear and precise language.\n",
    "        4. Avoid superfluous details and focus on the essential.\n",
    "        5. Strictly adhere to the 60-word limit.\n",
    "        6. Ensure the summary is coherent and self-contained.\n",
    "\n",
    "        Conversation: ```{texte}```\n",
    "\n",
    "        Summary (max 60 words):\n",
    "        \"\"\"\n",
    "        return self.openai_client.get_completion(prompt)\n",
    "\n",
    "    def summarize_free_format(self, texte):\n",
    "        \"\"\"\n",
    "        Generates a comprehensive summary of the given conversation.\n",
    "\n",
    "        Parameters:\n",
    "            texte (str): The conversation text to be summarized.\n",
    "\n",
    "        Returns:\n",
    "            str: The comprehensive summary of the conversation.\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        You are a highly skilled sales conversation analyst. Your task is to create a comprehensive and actionable summary of the following conversation, delimited by triple backticks.\n",
    "\n",
    "        Objective: \n",
    "        Generate a detailed summary that will be invaluable for sales managers, coaches, and team members involved in the deal.\n",
    "\n",
    "        Guidelines:\n",
    "        1. Identify and highlight the key points, Persons, outcomes, and any critical decisions made during the call.\n",
    "        2. Outline the main topics discussed and the flow of the conversation.\n",
    "        3. Capture important customer information, including needs, pain points, and objections.\n",
    "        4. Note any commitments made by either party or next steps agreed upon.\n",
    "        5. Highlight potential areas for improvement or coaching opportunities for the sales representative.\n",
    "        6. Include relevant context about the deal's status, size, or importance if mentioned.\n",
    "        7. Use clear, professional language and organize the summary in a logical structure.\n",
    "        8. Provide insights that could be useful for deal strategy or future interactions with the customer.\n",
    "\n",
    "        Your summary should be thorough enough to give a clear understanding of the call to someone who wasn't present, yet concise enough to be quickly digestible by busy professionals.\n",
    "\n",
    "        Conversation: ```{texte}```\n",
    "\n",
    "        Detailed Summary:\n",
    "        \"\"\"\n",
    "        return self.openai_client.get_completion(prompt)\n",
    "\n",
    "    def summarize_structured(self, texte):\n",
    "        \"\"\"\n",
    "        Generates a structured summary of the given conversation.\n",
    "\n",
    "        Parameters:\n",
    "            texte (str): The conversation text to be summarized.\n",
    "\n",
    "        Returns:\n",
    "            str: The structured summary of the conversation.\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        As an expert in business communication analysis, create a comprehensive and structured summary of the following conversation. Your summary should be valuable for team members who did not participate in the call, providing them with clear insights and actionable information.\n",
    "\n",
    "        Structure your summary as follows:\n",
    "\n",
    "        1. Purpose of the Call:\n",
    "        - Clearly state the main objective(s) of the conversation.\n",
    "        - Include any context or background information that sets the stage for the call.\n",
    "\n",
    "        2. Key Points Discussed:\n",
    "        - Provide a bulleted list of the main topics covered.\n",
    "        - For each point, include brief but essential details.\n",
    "        - Highlight any significant insights, challenges, or opportunities mentioned.\n",
    "\n",
    "        3. Results and Next Steps:\n",
    "        - Summarize the outcomes of the conversation.\n",
    "        - List any decisions made or conclusions reached.\n",
    "        - Outline the agreed-upon next steps or future plans.\n",
    "\n",
    "        4. Action Points:\n",
    "        - Create a clear, bulleted list of specific tasks or actions to be taken.\n",
    "        - For each action item, specify who is responsible (if mentioned) and any deadlines.\n",
    "        - Include any follow-up meetings or communications planned.\n",
    "\n",
    "        5. Additional Insights (optional):\n",
    "        - Note any underlying issues, potential risks, or opportunities not explicitly discussed but implied.\n",
    "        - Provide any strategic recommendations based on the conversation content.\n",
    "\n",
    "        Guidelines:\n",
    "        - Use clear, concise language.\n",
    "        - Focus on factual information and avoid personal interpretations unless specifically relevant.\n",
    "        - Ensure the summary is self-contained and understandable without additional context.\n",
    "        - Aim for a balance between comprehensiveness and brevity.\n",
    "\n",
    "        Conversation: ```{texte}```\n",
    "\n",
    "        Detailed Summary:\n",
    "        \"\"\"\n",
    "        return self.openai_client.get_completion(prompt)\n",
    "\n",
    "\n",
    "    \n",
    "openai_client = OpenAIClient()\n",
    "summarizer = Summarizer(openai_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicto_summary = {\n",
    "        \"60-word summary\": summarizer.summarize_60_words(texte),\n",
    "        \"Free-format summary\": summarizer.summarize_free_format(texte),\n",
    "        \"Structured summary\": summarizer.summarize_structured(texte)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"```spk0, spk1, and spk2 discuss Modjo's features, sales performance, and onboarding. They address call tagging, objection handling, and AI usage. Pricing and user feedback are key points. They plan a follow-up meeting for further discussion. The conversation emphasizes Modjo's potential for improving sales efficiency and collaboration.```\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicto_summary[\"60-word summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The conversation involved three participants: Celeste, Merlin, and Arthur. They discussed various topics related to improving sales performance, particularly through the use of Modjo, an AI tool. Celeste highlighted the importance of understanding the level of knowledge and objectives for the call. They touched on topics such as improving commercial performance through AI, workshops for handling objections, and tracking sales performance metrics like conversion rates and revenue targets.\\n\\nMerlin and Arthur shared insights on their operational processes, including conducting workshops, tracking objections, and setting sales targets. They discussed the challenges of note-taking during calls and the need for better tools to enhance productivity. The conversation also delved into the pricing model for Modjo and the potential for future product enhancements without additional costs.\\n\\nThe participants agreed to schedule a follow-up meeting for a detailed presentation of Modjo's features and onboarding process. They also discussed the importance of continuous product improvements and the need for effective communication and collaboration within the sales team. Overall, the conversation highlighted the potential benefits of using AI tools like Modjo to enhance sales performance and streamline processes.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicto_summary[\"Free-format summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1. Purpose of the Call:\\n- The main objective of the conversation was to discuss the performance improvement in commercial activities, particularly through the use of AI to enhance sales scripts and pitch demos.\\n- The call aimed to provide context from previous discussions and establish the purpose of the group call.\\n\\n2. Key Points Discussed:\\n- Discussion on improving commercial performance through AI, focusing on script similarity and pitch demo testing.\\n- Operational responsibilities shared between team members, with a focus on workshops and objection handling.\\n- Exploration of interactions with potential clients like Furnitures and SquareChair.\\n- Review of current sales performance metrics, including conversion rates and revenue targets.\\n- Challenges in tracking and analyzing sales contributions and objections.\\n- Introduction to Modjo's capabilities in call analysis, note-taking, and CRM integration.\\n- Business model discussions, including pricing, user licenses, and potential discounts.\\n- Consideration of onboarding processes and future product developments.\\n\\n3. Results and Next Steps:\\n- Agreement to schedule a follow-up meeting for a detailed presentation of Modjo's offerings and pricing.\\n- Confirmation of ongoing performance monitoring and improvement efforts, with a focus on leveraging AI tools for sales enhancement.\\n- Commitment to address challenges in note-taking, objection handling, and call analysis for improved sales effectiveness.\\n- Clarification on the business model and pricing structure for Modjo's services.\\n\\n4. Action Points:\\n- Schedule a follow-up meeting for a detailed presentation of Modjo's offerings and pricing (Celeste and team).\\n- Address challenges in note-taking and objection handling processes (CSM team).\\n- Monitor and improve sales performance metrics, including conversion rates and revenue targets (Sales team).\\n- Explore potential discounts and additional features for Modjo's services (Management team).\\n- Review and optimize onboarding processes for new users (Consultant team).\\n\\n5. Additional Insights:\\n- The conversation highlighted the importance of leveraging AI tools for sales performance improvement and operational efficiency.\\n- There is a need for better tracking and analysis of sales contributions, objections, and call interactions to enhance overall sales effectiveness.\\n- Future product developments and enhancements may focus on addressing specific sales challenges and improving user experience.\\n\\nOverall, the conversation emphasized the importance of utilizing technology and data-driven insights to drive sales performance and enhance customer interactions. The team displayed a collaborative approach towards addressing challenges and exploring opportunities for growth and improvement in their commercial activities.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicto_summary[\"Structured summary\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Question Anwering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using GPT-3.5-turbo,** implement in python question answering method that take as input a json like the one you were provided, and that must be able to perform the answer the following questions:\n",
    "\n",
    "1. What are the next steps?\n",
    "2. Was budget mentioned, if so what was the amount?\n",
    "3. Who is Lancelot? \n",
    "4. Which CRM does the prospect use? \n",
    "5. What are the main objections raised ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarketingResearchAssistant_v1:\n",
    "    \"\"\"\n",
    "    A virtual assistant for answering questions based on a given conversation using the OpenAI API.\n",
    "\n",
    "    Attributes:\n",
    "        openai_client (OpenAI): The OpenAI client instance.\n",
    "        model (str): The model used for generating responses.\n",
    "        system_message (dict): The system message containing the guidelines for generating responses.\n",
    "\n",
    "    Methods:\n",
    "        __init__(model): Initializes the assistant with the specified model.\n",
    "        rag(query, conversation): Generates a response to the query based on the given conversation.\n",
    "        set_model(model): Sets the model for the assistant.\n",
    "        get_model(): Returns the current model of the assistant.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model=\"gpt-3.5-turbo\"):\n",
    "        \"\"\"\n",
    "        Initializes the marketing research assistant with the specified model.\n",
    "\n",
    "        Parameters:\n",
    "            model (str): The model used for generating responses. Default is \"gpt-3.5-turbo\".\n",
    "        \"\"\"\n",
    "        self.openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "        self.model = model\n",
    "        self.system_message = {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are an expert AI assistant tasked with answering questions using only the information provided in the given conversation. Follow these guidelines: \"\n",
    "                \"1. Carefully analyze the question and the provided conversation.\"\n",
    "                \"2. Answer solely based on the information in the conversation. Do not make assumptions or add outside information.\"\n",
    "                \"3. If the answer is not in the conversation, clearly state 'I cannot answer this question based on the provided conversation.' and said why\"\n",
    "                \"4. Cite relevant parts of the conversation to support your answer.\"\n",
    "                \"5. If the conversation contains contradictory information, mention it and explain the different perspectives.\"\n",
    "                \"6. Structure your response logically:\"\n",
    "                \"a) Start with a direct sentence answering the question.\"\n",
    "                \"b) Provide additional details or explanations if necessary.\"\n",
    "                \"c) Conclude by summarizing the key points.\"\n",
    "                \"7. Limit your response to three sentences maximum, unless more details are absolutely necessary for a complete and accurate answer.\"\n",
    "                \"8. If you are uncertain about any element of your answer, clearly indicate your level of certainty.\"\n",
    "            )\n",
    "        }\n",
    "\n",
    "    def rag(self, query, conversation):\n",
    "        \"\"\"\n",
    "        Generates a response to the query based on the given conversation.\n",
    "\n",
    "        Parameters:\n",
    "            query (str): The question to be answered.\n",
    "            conversation (str): The conversation text to be analyzed.\n",
    "\n",
    "        Returns:\n",
    "            str: The generated response from the OpenAI API.\n",
    "        \"\"\"\n",
    "        messages = [\n",
    "            self.system_message,\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Question: {query}\\nConversation: {conversation}\"\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            response = self.openai_client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=messages,\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing the query: {e}\")\n",
    "            return None\n",
    "\n",
    "    def set_model(self, model):\n",
    "        \"\"\"\n",
    "        Sets the model for the assistant.\n",
    "\n",
    "        Parameters:\n",
    "            model (str): The model to be set.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "\n",
    "    def get_model(self):\n",
    "        \"\"\"\n",
    "        Returns the current model of the assistant.\n",
    "\n",
    "        Returns:\n",
    "            str: The current model used by the assistant.\n",
    "        \"\"\"\n",
    "        return self.model\n",
    "\n",
    "\n",
    "assistant = MarketingResearchAssistant_v1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answering questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The next steps involve setting up a meeting on Monday at 4:30 pm for a more in-depth discussion regarding Modjo, addressing questions about onboarding and product features. The pricing structure remains stable with no extra costs for additional features mentioned during the conversation.\\n\\nIn summary, the next steps include a detailed discussion on Monday at 4:30 pm to further explore Modjo's functionalities and onboarding processes. The pricing remains unchanged, ensuring no additional costs for new features.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are the next steps? \"\n",
    "assistant.rag(query, texte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The budget amount was not explicitly mentioned in the conversation. The discussion mainly focused on demonstrating the value proposition and the pricing model of the tool. There were references to a monthly price of 99 euros for five users, totaling around 495 euros without additional features or discounts. Further details were not provided regarding a specific budget amount mentioned.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Was budget mentioned, if so what was the amount? \"\n",
    "assistant.rag(query, texte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: Lancelot is not mentioned or discussed in the conversation provided. \\n\\nI cannot answer this question based on the provided conversation.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Who is Lancelot? \"\n",
    "assistant.rag(query, texte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: The prospect uses Hubspot as their CRM tool.  \\nIn the conversation, the salesperson mentions, \"Je suis à eux depuis trois mois maintenant et du coup, qui de mieux qu\\'un utilisateur Modjo pourra vous partager des insights,\" indicating that the prospect uses Hubspot as their CRM.  \\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Which CRM does the prospect use?  \"\n",
    "assistant.rag(query, texte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The main objections raised during the conversation pertain to the pricing and value proposition of the tool Modjo, with considerations about the ROI, the budget constraints, and the necessity for discounts or added features. Additionally, discussions around the effectiveness and setup process of the tool, especially regarding onboarding and future product developments, were also prominent topics. The conversation highlighted the importance of user involvement, trackable results, and the need for consistent performance improvement.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are the main objections raised ? \"\n",
    "assistant.rag(query, texte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2 (LangChain doc retriever with ChromaDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentProcessor:\n",
    "    \"\"\"\n",
    "    A class to process documents by loading, splitting, and creating a vector store.\n",
    "\n",
    "    Attributes:\n",
    "        api_key (str): The API key for OpenAI.\n",
    "        persist_directory (str): The directory to persist the vector store.\n",
    "        embedding (OpenAIEmbeddings): The embeddings instance from OpenAI.\n",
    "\n",
    "    Methods:\n",
    "        load_and_split_documents(file_path): Loads and splits documents from the given file path.\n",
    "        create_vector_store(texts): Creates and persists a vector store from the given texts.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the DocumentProcessor with the OpenAI API key and embedding.\n",
    "        \"\"\"\n",
    "        self.api_key = OPENAI_API_KEY\n",
    "        self.persist_directory = 'data'\n",
    "        self.embedding = OpenAIEmbeddings()\n",
    "\n",
    "    def load_and_split_documents(self, file_path):\n",
    "        \"\"\"\n",
    "        Loads and splits documents from the given file path.\n",
    "\n",
    "        Parameters:\n",
    "            file_path (str): The path to the document file.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of split document chunks.\n",
    "        \"\"\"\n",
    "        loader = TextLoader(file_path)\n",
    "        documents = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200,\n",
    "            separators=[\"\\n\"])\n",
    "        return text_splitter.split_documents(documents)\n",
    "\n",
    "    def create_vector_store(self, texts):\n",
    "        \"\"\"\n",
    "        Creates and persists a vector store from the given texts.\n",
    "\n",
    "        Parameters:\n",
    "            texts (list): A list of text documents.\n",
    "\n",
    "        Returns:\n",
    "            Chroma: The created and persisted vector store.\n",
    "        \"\"\"\n",
    "        vectordb = Chroma.from_documents(\n",
    "            documents=texts,\n",
    "            embedding=self.embedding,\n",
    "            persist_directory=self.persist_directory\n",
    "        )\n",
    "        vectordb.persist()\n",
    "        return Chroma(\n",
    "            persist_directory=self.persist_directory,\n",
    "            embedding_function=self.embedding\n",
    "        )\n",
    "\n",
    "class MarketingResearchAssistant_v2:\n",
    "    \"\"\"\n",
    "    A virtual assistant for answering questions based on a given context using a retrieval chain.\n",
    "\n",
    "    Attributes:\n",
    "        llm (ChatOpenAI): The language model used for generating responses.\n",
    "\n",
    "    Methods:\n",
    "        create_retrieval_chain(vectordb): Creates a retrieval chain using the given vector store.\n",
    "        process_query(chain, query): Processes the query using the given chain and returns the response.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the marketing research assistant with a ChatOpenAI instance.\n",
    "        \"\"\"\n",
    "        self.llm = ChatOpenAI(temperature=0.0, api_key=OPENAI_API_KEY)\n",
    "\n",
    "    def create_retrieval_chain(self, vectordb):\n",
    "        \"\"\"\n",
    "        Creates a retrieval chain using the given vector store.\n",
    "\n",
    "        Parameters:\n",
    "            vectordb (Chroma): The vector store to be used for retrieval.\n",
    "\n",
    "        Returns:\n",
    "            RetrievalChain: The created retrieval chain.\n",
    "        \"\"\"\n",
    "        retriever = vectordb.as_retriever()\n",
    "        system_prompt = (\n",
    "            \"You are an expert AI assistant tasked with answering questions using only the information provided in the given context. Follow these guidelines: \"\n",
    "            \"1. Carefully analyze the question and the provided context.\"\n",
    "            \"2. Answer solely based on the information in the context. Do not make assumptions or add outside information.\"\n",
    "            \"3. If the answer is not in the context, clearly state 'I cannot answer this question based on the provided context.' and said why\"\n",
    "            \"4. Cite relevant parts of the context to support your answer.\"\n",
    "            \"5. If the context contains contradictory information, mention it and explain the different perspectives.\"\n",
    "            \"6. Structure your response logically:\"\n",
    "            \"a) Start with a direct sentence answering the question.\"\n",
    "            \"b) Provide additional details or explanations if necessary.\"\n",
    "            \"c) Conclude by summarizing the key points.\"\n",
    "            \"7. Limit your response to three sentences maximum, unless more details are absolutely necessary for a complete and accurate answer.\"\n",
    "            \"8. If you are uncertain about any element of your answer, clearly indicate your level of certainty.\"\n",
    "            \"Context: {context}\"\n",
    "        )\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", system_prompt),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ])\n",
    "        question_answer_chain = create_stuff_documents_chain(self.llm, prompt)\n",
    "        return create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "    def process_query(self, chain, query):\n",
    "        \"\"\"\n",
    "        Processes the query using the given chain and returns the response.\n",
    "\n",
    "        Parameters:\n",
    "            chain (RetrievalChain): The retrieval chain to be used for processing the query.\n",
    "            query (str): The query to be processed.\n",
    "\n",
    "        Returns:\n",
    "            str: The generated response from the retrieval chain.\n",
    "        \"\"\"\n",
    "        llm_response = chain.invoke({\"input\": query})\n",
    "        return llm_response['answer']\n",
    "\n",
    "\n",
    "doc_processor = DocumentProcessor()\n",
    "query_processor = MarketingResearchAssistant_v2()\n",
    "\n",
    "# Traitement des documents\n",
    "texts = doc_processor.load_and_split_documents(\"data/conversation.txt\")\n",
    "vectordb = doc_processor.create_vector_store(texts)\n",
    "\n",
    "# Traitement de la requête\n",
    "chain = query_processor.create_retrieval_chain(vectordb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answering questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cannot answer this question based on the provided context.\n"
     ]
    }
   ],
   "source": [
    "result = query_processor.process_query(chain, \"Was budget mentioned, if so what was the amount?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The next steps involve progressing towards a specific number by 2024 to achieve the set objective, despite a significant gap between the high and low points. The focus seems to be on reaching a certain target to fulfill the goal, indicating a need for strategic planning and actions to bridge the existing gap.\n"
     ]
    }
   ],
   "source": [
    "result = query_processor.process_query(chain, \"What are the next steps?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cannot answer this question based on the provided context.\n"
     ]
    }
   ],
   "source": [
    "result = query_processor.process_query(chain, \"Who is Lancelot?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cannot answer this question based on the provided context.\n"
     ]
    }
   ],
   "source": [
    "result = query_processor.process_query(chain, \"Which CRM does the prospect use?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cannot answer this question based on the provided context.\n"
     ]
    }
   ],
   "source": [
    "result = query_processor.process_query(chain, \"What are the main objections raised?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concise comparison of MarketingResearchAssistant v1 and v2 methods:\n",
    "\n",
    "Approach:\n",
    "- v1: Direct use of OpenAI API\n",
    "- v2: Retrieval chain with vector storage\n",
    "\n",
    "Data processing:\n",
    "- v1: No preprocessing, entire conversation provided per query\n",
    "- v2: Document preprocessing (loading, splitting, vectorization)\n",
    "\n",
    "Storage and retrieval:\n",
    "- v1: No storage, on-the-fly processing\n",
    "- v2: Persistent vector storage (Chroma)\n",
    "\n",
    "v2 advantages: Increased efficiency for large volumes, precise contextual retrieval, potentially faster for repeated queries\n",
    "\n",
    "v2 disadvantages: Increased complexity, higher initial resource requirements\n",
    "\n",
    "Both methods maintain similar guidelines for generating consistent and structured responses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
